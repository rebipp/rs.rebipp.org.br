{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A note on deprecation**\n",
    "\n",
    "Deprecation typical should not occur - it is a symptom of failure in planning or design. If at all possible, term labels or definitions should be modified without actually making the URI of the term be useless. However, there may be circumstances where deprecation is necessary. For example, a temporary term might be introduced for testing or utility and then be replaced by another term in a stable vocabulary.  \n",
    "\n",
    "![term lifespan](https://raw.githubusercontent.com/tdwg/vocab/master/graphics/version-model.png)\n",
    "\n",
    "The diagram above represents the lifespan of a term. In the case of deprecation, the tip of the arrow at the right represents the date of death of the term (the date it's deprecated).  Note that the end of the term's life is not attended by the birth of a new version of the same term.  Optimally, a deprecated term would be replaced by a different term, and that deprecation date would be the date of issue of the first version of the new term.  \n",
    "\n",
    "The implications of this are that the current term will have a last modified date that is the date of its deprecation.  That makes sense because the current term metadata will be changed on that date to give it an owl:deprecated value of true.  The value of tdwgutility:status of the most recent term will be changed from \"recommended\" to \"deprecated\".  \n",
    "\n",
    "The other metadata changes that will be related to the deprecation is a record of the replacement. The new term that is replacing the deprecated term should manually have a value added in the \"repalces_term\" column that is the deprecated term's URI. The \"x-replacements.csv\" file in the deprecated term's term list folder should have a link between the replacing term URI and the local name of the replaced term.  \n",
    "\n",
    "The \"x-version-replacements.csv\" file in the \"x-versions\" directory for the deprecated term's term list should link the deprecated term version's local name to the version URI of the replacing version of the new term. The \"x-versions.csv\" table for the new term should have a value in the replaces_version column of the term URI of the term that was replaced. The status of the replaced term should also be manually changed to `deprecated`.\n",
    "\n",
    "Because these changes do not fit into the normal term modification workflow, most of them will need to be made manually. However, changes to the term list metadata can be made using this script. If other terms on the term list are going to be modified, the cells in section 5 will be run anyway. If the term deprecation is the only change to be made to the term list, create a changes file that contains only headers (no data rows), then run sections 1 and 2, then skip to section 5. Do the steps in section 5 except for the ones noted as requiring manual editing for deprecation.  Whether sections 6 and 7 need to be run depends on whether they were already run for another term list in the vocabulary or if the term list isn't part of a vocabulary (e.g. tdwgutility: terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Initial setup\n",
    "\n",
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Steve Baskauf 2020-06-29 CC0\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaceUri = 'http://rs.tdwg.org/dwcpw/values/'\n",
    "database = 'pathway'\n",
    "date_issued = '2020-06-29'\n",
    "local_offset_from_utc = '-05:00'\n",
    "versions = database + '-versions'\n",
    "modifications_filename = 'pathway-revised.csv'\n",
    "vocab_type = 3 # 1 is simple vocabulary, 2 is simple controlled vocabulary, 3 is c.v. with broader hierarchy\n",
    "version_namespace = namespaceUri + 'version/'\n",
    "\n",
    "# For borrowed terms, specify the termlist URI here:\n",
    "\n",
    "termlist_uri = ''\n",
    "\n",
    "# For terms minted by TDWG that follow URI pattern conventions, leave this the empty string and the \n",
    "# termlist_uri will be set to the namespace URI.\n",
    "# In both cases the termlist version URI will be constructed from the namespace URI\n",
    "if termlist_uri == '':\n",
    "    termlist_uri = namespaceUri\n",
    "\n",
    "# namespace is actually the last component of the termlist URI, not of the namespace URI\n",
    "pieces = termlist_uri.split('/')\n",
    "namespace = pieces[len(pieces)-2]\n",
    "vocabulary = pieces[len(pieces)-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsv(filename):\n",
    "    fileObject = open(filename, 'r', newline='', encoding='utf-8')\n",
    "    readerObject = csv.reader(fileObject)\n",
    "    array = []\n",
    "    for row in readerObject:\n",
    "        array.append(row)\n",
    "    fileObject.close()\n",
    "    return array\n",
    "\n",
    "def writeCsv(fileName, array):\n",
    "    fileObject = open(fileName, 'w', newline='', encoding='utf-8')\n",
    "    writerObject = csv.writer(fileObject)\n",
    "    for row in array:\n",
    "        writerObject.writerow(row)\n",
    "    fileObject.close()\n",
    "\n",
    "    # returns a list with first item Boolean and second item the index\n",
    "def findColumnWithHeader(header_row_list, header_label):\n",
    "    found = False\n",
    "    for column_number in range(0, len(header_row_list)):\n",
    "        if header_row_list[column_number] == header_label:\n",
    "            found = True\n",
    "            found_column = column_number\n",
    "    if found:\n",
    "        return [True, found_column]\n",
    "    else:\n",
    "        return [False, 0]\n",
    "    \n",
    "def isoTime(offset):\n",
    "    currentTime = datetime.datetime.now()\n",
    "    return currentTime.strftime(\"%Y-%m-%dT%H:%M:%S\") + offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Generate files in database directories (new term lists only)\n",
    "\n",
    "There are a number of files that need to exist in the current terms database directory and the versions database directory. This part of the script generates them from templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mutable column headers from the modifications file\n",
    "modifications_metadata = readCsv(modifications_filename)\n",
    "mutable_header = modifications_metadata[0][1:len(modifications_metadata[0])]\n",
    "\n",
    "# create database directories\n",
    "try:\n",
    "    os.mkdir('../' + database)\n",
    "    os.mkdir('../' + database + '-versions')\n",
    "# do nothing if there is an error (i.e. they already exist)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# copy files needed in the current terms database directory\n",
    "endings = ['-classes.csv', '-replacements-classes.csv', '-replacements-column-mappings.csv', '-replacements.csv', '-versions-classes.csv', '-versions-column-mappings.csv', '-versions.csv']\n",
    "source_path = 'files_for_new/current_terms/'\n",
    "for file_ending in endings:\n",
    "    source = source_path + 'template' + file_ending\n",
    "    destination = '../' + database + '/' + database + file_ending\n",
    "    dest_path = shutil.copyfile(source, destination)\n",
    "dest_path = shutil.copyfile(source_path + 'namespace.csv', '../' + database + '/namespace.csv')\n",
    "\n",
    "# select current terms column mapping file appropriate for modifications spreadsheet\n",
    "if vocab_type == 1: # simple vocabulary\n",
    "    in_file = 'simple-vocabulary-column-mappings.csv'\n",
    "elif vocab_type == 2: # simple controlled vocabulary\n",
    "    in_file = 'simple-cv-column-mappings.csv'\n",
    "elif vocab_type == 3: # c.v. with skos:broader hierarchy\n",
    "    in_file = 'cv-hierarchy-column-mappings.csv'\n",
    "else: # This should not happen\n",
    "    in_file = 'simple-vocabulary-column-mappings.csv'\n",
    "\n",
    "frame = pd.read_csv(source_path + in_file, na_filter=False)\n",
    "for index,row in frame.iterrows():\n",
    "    # replace the placeholder IRIs with the namespace IRI\n",
    "    if row['header'] == 'skos_inScheme':\n",
    "        frame.at[index,'value'] = namespaceUri\n",
    "    if row['header'] == 'skos_broader':\n",
    "        frame.at[index,'value'] = namespaceUri\n",
    "frame.to_csv('../' + database + '/' + database + '-column-mappings.csv', index=False)\n",
    "    \n",
    "# set the core class file and domain root in the constants.csv configuration file\n",
    "frame = pd.read_csv(source_path + 'constants.csv', na_filter=False)\n",
    "frame.at[0,'domainRoot'] = namespaceUri\n",
    "frame.at[0,'coreClassFile'] = database + '.csv'\n",
    "frame.to_csv('../' + database + '/constants.csv', index=False)\n",
    "    \n",
    "# set the versions and replacements filenames in the linked-classes.csv file\n",
    "frame = pd.read_csv(source_path + 'linked-classes.csv', na_filter=False)\n",
    "for index,row in frame.iterrows():\n",
    "    # replace the placeholder filenames with the actual linked file names\n",
    "    if row['link_column'] == 'term_localName':\n",
    "        frame.at[index,'filename'] = database + '-versions.csv'\n",
    "    if row['link_column'] == 'replaced_term_localName':\n",
    "        frame.at[index,'filename'] = database + '-replacements.csv'\n",
    "frame.to_csv('../' + database + '/linked-classes.csv', index=False)\n",
    "    \n",
    "# create header row for current terms metadata CSV\n",
    "current_terms_header = ['document_modified', 'term_localName', 'term_isDefinedBy', 'term_created', 'term_modified', 'term_deprecated', 'replaces_term', 'replaces1_term', 'replaces2_term'] + mutable_header\n",
    "current_terms_table = [current_terms_header]\n",
    "file_path = '../' + database + '/' + database + '.csv'\n",
    "writeCsv(file_path, current_terms_table)\n",
    "\n",
    "\n",
    "# copy files needed in the versions database directory\n",
    "endings = ['-versions-classes.csv', '-versions-replacements-classes.csv', '-versions-replacements-column-mappings.csv', '-versions-replacements.csv']\n",
    "source_path = 'files_for_new/versions/'\n",
    "for file_ending in endings:\n",
    "    source = source_path + 'template' + file_ending\n",
    "    destination = '../' + database + '-versions/' + database + file_ending\n",
    "    dest_path = shutil.copyfile(source, destination)\n",
    "#dest_path = shutil.copyfile(source_path + 'linked-classes.csv', '../' + database + '-versions/linked-classes.csv')\n",
    "dest_path = shutil.copyfile(source_path + 'namespace.csv', '../' + database + '-versions/namespace.csv')\n",
    "\n",
    "# select versions column mapping file appropriate for modifications spreadsheet\n",
    "if vocab_type == 1: # simple vocabulary\n",
    "    in_file = 'simple-vocabulary-versions-column-mappings.csv'\n",
    "elif vocab_type == 2: # simple controlled vocabulary\n",
    "    in_file = 'simple-cv-versions-column-mappings.csv'\n",
    "elif vocab_type == 3: # c.v. with skos:broader hierarchy\n",
    "    in_file = 'cv-hierarchy-versions-column-mappings.csv'\n",
    "else: # This should not happen\n",
    "    in_file = 'simple-vocabulary-versions-column-mappings.csv'\n",
    "\n",
    "frame = pd.read_csv(source_path + in_file, na_filter=False)\n",
    "for index,row in frame.iterrows():\n",
    "    # replace the placeholder IRIs with the namespace IRI\n",
    "    if row['header'] == 'skos_inScheme':\n",
    "        frame.at[index,'value'] = namespaceUri\n",
    "    if row['header'] == 'skos_broader':\n",
    "        frame.at[index,'value'] = namespaceUri\n",
    "    if row['header'] == 'term_localName':\n",
    "        frame.at[index,'value'] = namespaceUri\n",
    "frame.to_csv('../' + database + '-versions/' + database + '-versions-column-mappings.csv', index=False)\n",
    "\n",
    "# set the core class file and domain root in the constants.csv configuration file\n",
    "frame = pd.read_csv(source_path + 'constants.csv', na_filter=False)\n",
    "frame.at[0,'domainRoot'] = namespaceUri + 'version/'\n",
    "frame.at[0,'coreClassFile'] = database + '-versions.csv'\n",
    "frame.to_csv('../' + database + '-versions/constants.csv', index=False)\n",
    "\n",
    "# set the versions and replacements filenames in the linked-classes.csv file\n",
    "frame = pd.read_csv(source_path + 'linked-classes.csv', na_filter=False)\n",
    "for index,row in frame.iterrows():\n",
    "    # replace the placeholder filename with the actual linked file name\n",
    "    if row['link_column'] == 'replaced_version_localName':\n",
    "        frame.at[index,'filename'] = database + '-versions-replacements.csv'\n",
    "frame.to_csv('../' + database + '-versions/linked-classes.csv', index=False)\n",
    "\n",
    "# create header row for versions metadata CSV\n",
    "versions_header = ['document_modified', 'version', 'versionLocalName', 'version_isDefinedBy', 'version_issued', 'version_status', 'replaces_version', 'replaces1_version', 'replaces2_version'] + mutable_header + ['term_localName']\n",
    "versions_table = [versions_header]\n",
    "file_path = '../' + database + '-versions/' + database + '-versions.csv'\n",
    "writeCsv(file_path, versions_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Extract information from metadata files\n",
    "\n",
    "**Notes for all tables:** row 0 (the first row) is a header row. The columns whose headers contain `replaces1_` and `replaces2_` are used in the uncommon situation where a term or version replaces more than one other term or version.  In such cases, the tables would need to be modified manually.  \n",
    "\n",
    "The table containing the **modifications** (term additions and changes) looks like this:\n",
    "\n",
    "![](images/mods-table.png)\n",
    "\n",
    "The `term_localName` column is the primary key for this table.\n",
    "\n",
    "The table containing **current terms metadata** looks like this:\n",
    "\n",
    "![](images/current-terms-table1.png)\n",
    "![](images/current-terms-table2.png)\n",
    "\n",
    "Notice that all of the column headers from `label` onwards to the right are the same as those in the modifications table. The column headers to the left of `label` are ideosyncratic for the current terms table type and must be handled specially.  The `term_localName` column is the primary key for this table.  The `term_deprecated` and `replaces_term` columns are for unusual situations and aren't managed by this script.  They would need to be edited manually when those situations occur.\n",
    "\n",
    "The table containing **versions metadata** looks like this:\n",
    "\n",
    "![](images/versions-table1.png)\n",
    "![](images/versions-table2.png)\n",
    "\n",
    "As with the current terms table, all of the column headers from `label` onwards to the right are the same as the previous two tables. The column headers to the left of `label` are ideosyncratic for the table type and must be handled specially. The `versionLocalName` column is the primary key for this table.  The `term_localName` column is a foreign key that relates rows in this table to rows in the other two tables.  \n",
    "\n",
    "## 2.1 Read in the tables of current terms and of modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_metadata_filename = '../' + database + '/' + database + '.csv'\n",
    "terms_metadata = readCsv(terms_metadata_filename)\n",
    "\n",
    "modifications_metadata = readCsv(modifications_filename)\n",
    "print('Current terms table headers: ', terms_metadata[0])\n",
    "print()\n",
    "print('Modifications table headers: ', modifications_metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script loads data only on the basis of the column names and not their position.  So a number of variables are defined that hold the column numbers for various fields.  \n",
    "\n",
    "Find which column numbers in the modifications file and the metadata file hold the term local name.  This column is the primary key for the table and therefore is used to match rows for terms that need to be modified with the corresponding rows in the current term metadata table.  The `term_localName` column is the only one in the modifications table that is not potentially a vocabulary-specific metadata field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = findColumnWithHeader(modifications_metadata[0], 'term_localName')\n",
    "if result[0] == False:\n",
    "    print('The modifications file does not have a term_localName column')\n",
    "    sys.exit()\n",
    "else:\n",
    "    mods_local_name = result[1]\n",
    "\n",
    "# don't error trap here because all existing files should have a local name column header\n",
    "result = findColumnWithHeader(terms_metadata[0], 'term_localName')\n",
    "metadata_localname_column = result[1]\n",
    "print('Modifications table local name column: ', mods_local_name)\n",
    "print('Term metadata table local name column: ', metadata_localname_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the local names of terms to be added or modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_term_localName = []\n",
    "for term_number in range(1, len(modifications_metadata)):\n",
    "    mods_term_localName.append(modifications_metadata[term_number][mods_local_name])\n",
    "print(mods_term_localName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which terms are new terms and which are modified old terms.  Create a list for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms = []\n",
    "modified_terms = []\n",
    "for test_term in mods_term_localName:\n",
    "    found = False\n",
    "    for term in terms_metadata:\n",
    "        if test_term == term[metadata_localname_column]:\n",
    "            found = True\n",
    "            modified_terms.append(test_term)\n",
    "    if not found:\n",
    "        new_terms.append(test_term)\n",
    "print('New terms: ', new_terms)\n",
    "print('Modified terms: ', modified_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Update versions-related metadata (non-borrowed only)\n",
    "\n",
    "**Note:** Skip the entire section 3 for borrowed terms that do not have versions.\n",
    "\n",
    "The master versions metadata table (in the `xx-versions` directory) is used to generate metadata about versions.  The versions join table (in the current terms directory) is a minimal joins table used to generate the `hasVersion` links for current terms.  The versions replacements table is used to generate `dcterms:replaces` and `dcterms:isReplacedBy` links for version metadata records.\n",
    "\n",
    "Dublin Core terms are a special case. They have versions, but those versions are managed by DCMI. So updating things like examples in our metadata cannot trigger new term version IRIs. The term version metadata must just be edited manually to reflect the changes in TDWG-specific metadata rather than using parts 3.x of this script.\n",
    "\n",
    "## 3.1 Load master versions metadata and determine positions of special columns\n",
    "\n",
    "Read in the term versions metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_versions_metadata_filename = '../' + versions + '/' + versions + '.csv'\n",
    "term_versions_metadata = readCsv(term_versions_metadata_filename)\n",
    "print('Version headers: ', term_versions_metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the positions of the ideosyncratic version columns.  Recall:\n",
    "\n",
    "![](images/versions-table1.png)\n",
    "![](images/versions-table2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_modified = findColumnWithHeader(term_versions_metadata[0], 'document_modified')[1]\n",
    "version_column = findColumnWithHeader(term_versions_metadata[0], 'version')[1]\n",
    "version_local_name = findColumnWithHeader(term_versions_metadata[0], 'versionLocalName')[1]\n",
    "version_isDefinedBy = findColumnWithHeader(term_versions_metadata[0], 'version_isDefinedBy')[1]\n",
    "version_issued = findColumnWithHeader(term_versions_metadata[0], 'version_issued')[1]\n",
    "version_status = findColumnWithHeader(term_versions_metadata[0], 'version_status')[1]\n",
    "replaces_version = findColumnWithHeader(term_versions_metadata[0], 'replaces_version')[1]\n",
    "version_term_local_name_column = findColumnWithHeader(term_versions_metadata[0], 'term_localName')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Supersede old versions of the modified terms\n",
    "\n",
    "Go through each version and supersede any that match the local names of the modified terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rows in versions table to be superseded:')\n",
    "for term in modified_terms:\n",
    "    for version_row in range(1, len(term_versions_metadata)):\n",
    "        if term_versions_metadata[version_row][version_term_local_name_column] == term and term_versions_metadata[version_row][version_status] == 'recommended':\n",
    "            print(version_row, term)\n",
    "            term_versions_metadata[version_row][version_status] = 'superseded'\n",
    "            term_versions_metadata[version_row][version_modified] = isoTime(local_offset_from_utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Create new versions of new and modified terms\n",
    "\n",
    "Make sure that all columns in modified terms file are in the term versions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in modifications_metadata[0]:\n",
    "    result = findColumnWithHeader(term_versions_metadata[0], column)\n",
    "    if result[0] == False:\n",
    "        print('The versions file is missing the ', column, ' column.')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the versions join table, which looks like this:\n",
    "\n",
    "![](images/version-joins-table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions_join_table_filename = '../' + database + '/' + versions + '.csv'\n",
    "versions_join_table = readCsv(versions_join_table_filename)\n",
    "print('Versions join table headers: ', versions_join_table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new versions and new version joins lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newVersions = []\n",
    "newVersionJoins = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a row in the new term versions list for the added or modified terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row_number in range(1, len(modifications_metadata)):\n",
    "    newVersion = []\n",
    "    # create a column for every column in the term version file\n",
    "    for column in term_versions_metadata[0]:\n",
    "        # find the column in the modifications file that matches the version column and add its value\n",
    "        result = findColumnWithHeader(modifications_metadata[0], column)\n",
    "        if result[0] == True:\n",
    "            newVersion.append(modifications_metadata[row_number][result[1]])\n",
    "        else:\n",
    "            newVersion.append('')\n",
    "    # set the modification dateTime for the newly created version\n",
    "    newVersion[version_modified] = isoTime(local_offset_from_utc)\n",
    "    newVersions.append(newVersion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert metadata specific to the new versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rowNumber in range(0, len(newVersions)):\n",
    "    # need to add one to the row of modifications_metadata because it includes a header row\n",
    "    currentTermLocalName = modifications_metadata[rowNumber + 1][mods_local_name]\n",
    "    newVersions[rowNumber][version_issued] = date_issued\n",
    "    newVersions[rowNumber][version_status] = 'recommended'\n",
    "    newVersions[rowNumber][version_local_name] = currentTermLocalName + '-' + date_issued\n",
    "    newVersions[rowNumber][version_isDefinedBy] = version_namespace\n",
    "    newVersions[rowNumber][version_column] = version_namespace + currentTermLocalName + '-' + date_issued\n",
    "\n",
    "    # if the new version replaces an older one for the term, we need to provide a value for the `replaces_version` column\n",
    "    if currentTermLocalName in modified_terms:\n",
    "        # look through metadata for old versions to find the most recent version of the term\n",
    "        mostRecent = 'a' # start with a string value earlier in alphabetization than any term version URI\n",
    "        for version_row in range(1, len(term_versions_metadata)):\n",
    "            if term_versions_metadata[version_row][version_term_local_name_column] == currentTermLocalName:\n",
    "                # Make it the mostRecent if it's later than the previous mostRecent\n",
    "                if term_versions_metadata[version_row][version_column] > mostRecent:\n",
    "                    mostRecent = term_versions_metadata[version_row][version_column]\n",
    "        # insert the most recent version found into the appropriate column\n",
    "        newVersions[rowNumber][replaces_version] = mostRecent\n",
    "    \n",
    "    # create a join record for each new version and add it to the list of new joins\n",
    "    newVersionJoin =[ newVersions[rowNumber][version_column], modifications_metadata[rowNumber + 1][mods_local_name] ]\n",
    "    newVersionJoins.append(newVersionJoin)\n",
    "\n",
    "print(newVersions)\n",
    "print()\n",
    "print(newVersionJoins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the new versions to the old version tables and save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_term_versions_metadata = term_versions_metadata + newVersions\n",
    "writeCsv('../' + versions + '/' + versions + '.csv', revised_term_versions_metadata)\n",
    "\n",
    "revised_term_versions_joins = versions_join_table + newVersionJoins\n",
    "writeCsv('../' + database + '/' + versions + '.csv', revised_term_versions_joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Update the versions replacements table\n",
    "\n",
    "The versions replacements table links a newly created version of a modified term to the previous version it is replacing. \n",
    "\n",
    "Since new terms do not have any previous versions, they will not have entries in this table. Thus replacement entries only need to be generated for terms on the `modified_terms` list.\n",
    "\n",
    "The script only handles cases where there is a new version of a term with the same local name.  In cases where an old term is deprecated and is replaced by a new term with a different local name, the replacement table will need to be updated manually.\n",
    "\n",
    "Here's an example of what a replacements table looks like:\n",
    "\n",
    "![](images/version-replacements-table.png)\n",
    "\n",
    "Open it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions_replacements_table_filename = '../' + versions + '/' + versions + '-replacements.csv'\n",
    "versions_replacements_table = readCsv(versions_replacements_table_filename)\n",
    "print('Versions replacements table headers: ', versions_replacements_table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most recent previous version for each term on the `modified_terms` list and generate a replacement record for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to hold the newly generated replacements rows\n",
    "newReplacements = []\n",
    "\n",
    "for modifiedTerm in modified_terms:\n",
    "    # generate the newly created version URI for the modified term\n",
    "    newVersion = version_namespace + modifiedTerm  + '-' + date_issued\n",
    "    # step through the list of previous versions and find the one with the most recent issued date\n",
    "    mostRecent = 'a'\n",
    "    count = 0\n",
    "    for oldVersion in versions_join_table:\n",
    "        if count > 0: # skip the header row\n",
    "            # the second column in the join table is the term local name\n",
    "            if oldVersion[1] == modifiedTerm:\n",
    "                # the first column in the join table is the full version URI\n",
    "                if oldVersion[0] > mostRecent:\n",
    "                    mostRecent = oldVersion[0]\n",
    "        count +=1\n",
    "    # once the most revent version URI is found, we need to extract the local name\n",
    "    mostRecentLocal = mostRecent.split('/')[6]\n",
    "    newReplacements.append([newVersion, mostRecentLocal])\n",
    "print(newReplacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the new replacement list to the existing table and save as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_versions_replacements_table = versions_replacements_table + newReplacements\n",
    "writeCsv('../' + versions + '/' + versions + '-replacements.csv', revised_versions_replacements_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Process current terms metadata\n",
    "\n",
    "## 4.1 determine positions of special columns\n",
    "\n",
    "Find the positions of the ideosyncratic current terms columns (table already loaded). Recall:\n",
    "\n",
    "![](images/current-terms-table1.png)\n",
    "![](images/current-terms-table2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_modified_dateTime = findColumnWithHeader(terms_metadata[0], 'document_modified')[1]\n",
    "term_localName = findColumnWithHeader(terms_metadata[0], 'term_localName')[1]\n",
    "term_modified = findColumnWithHeader(terms_metadata[0], 'term_modified')[1]\n",
    "term_created = findColumnWithHeader(terms_metadata[0], 'term_created')[1]\n",
    "term_isDefinedBy = findColumnWithHeader(terms_metadata[0], 'term_isDefinedBy')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Modify current terms metadata table\n",
    "\n",
    "Each item in the term modifications list will either modify existing term metadata or add new term metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Changed current terms rows: ')\n",
    "# step through each row in the modification metadata table and modify existing current terms when applicable\n",
    "for mods_rownumber in range(1, len(modifications_metadata)):\n",
    "    mods_localname_string = modifications_metadata[mods_rownumber][mods_local_name]\n",
    "    modified = False\n",
    "    for term_name in modified_terms:\n",
    "        # only make a modification if it's on the list of terms to be modified\n",
    "        if mods_localname_string == term_name:\n",
    "            modified = True\n",
    "    # this section of code modifies existing terms\n",
    "    if modified:\n",
    "        # find the row in the terms metadata file for the term to be modified\n",
    "        for term_rownumber in range(1, len(terms_metadata)):\n",
    "            if mods_localname_string == terms_metadata[term_rownumber][term_localName]:\n",
    "                terms_metadata[term_rownumber][term_modified_dateTime] = isoTime(local_offset_from_utc)\n",
    "                terms_metadata[term_rownumber][term_modified] = date_issued\n",
    "                # replace every column that's in the modifications metadata\n",
    "                for column_number in range(0, len(modifications_metadata[0])):\n",
    "                    # find the column in the current terms metadata table that matches the modifications column and replace the current term's value\n",
    "                    result = findColumnWithHeader(terms_metadata[0], modifications_metadata[0][column_number])\n",
    "                    if result[0] == True:\n",
    "                        terms_metadata[term_rownumber][result[1]] = modifications_metadata[mods_rownumber][column_number]\n",
    "                    else:\n",
    "                        pass # this shouldn't really happen since there already was a check that all columns existed in the versions table\n",
    "                print(terms_metadata[term_rownumber])\n",
    "    # this section of code adds new term metadata\n",
    "    else: \n",
    "        newTermRow = []\n",
    "        for column in range(0, len(terms_metadata[0])):\n",
    "            newTermRow.append('')\n",
    "        newTermRow[term_modified_dateTime] = isoTime(local_offset_from_utc)\n",
    "        newTermRow[term_modified] = date_issued\n",
    "        newTermRow[term_created] = date_issued\n",
    "        newTermRow[term_isDefinedBy] = namespaceUri\n",
    "        # replace every column that's in the modifications metadata\n",
    "        for column_number in range(0, len(modifications_metadata[0])):\n",
    "            # find the column in the current terms metadata table that matches the modifications column and replace the current term's value\n",
    "            result = findColumnWithHeader(terms_metadata[0], modifications_metadata[0][column_number])\n",
    "            if result[0] == True:\n",
    "                newTermRow[result[1]] = modifications_metadata[mods_rownumber][column_number]\n",
    "            else:\n",
    "                pass # this shouldn't really happen since there already was a check that all columns existed in the versions table\n",
    "        print(newTermRow)\n",
    "        terms_metadata.append(newTermRow)\n",
    "writeCsv('../' + database + '/' + database + '.csv', terms_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Generate new term list version\n",
    "\n",
    "These changes to terms trigger a new version of the term list.  The term lists are in the special directories `term-lists` and `term-lists-versions`.  \n",
    "\n",
    "## 5.1 Open tables\n",
    "\n",
    "The master term lists and term list versions joins tables are similar to the terms metadata tables and their joins tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_table_filename = '../term-lists/term-lists.csv'\n",
    "term_lists_table = readCsv(term_lists_table_filename)\n",
    "print('Term lists table headers and first row: ', term_lists_table[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_versions_joins_filename = '../term-lists/term-lists-versions.csv'\n",
    "term_lists_versions_joins = readCsv(term_lists_versions_joins_filename)\n",
    "print('Term lists versions joins table headers and first row: ', term_lists_versions_joins[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `term-list-members.csv` file is used to create the one:many links between the term list and the terms that are members of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_members_filename = '../term-lists/term-lists-members.csv'\n",
    "term_lists_members = readCsv(term_lists_members_filename)\n",
    "print('Term lists members table headers and first row: ', term_lists_members[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master term list versions metadata table is used to generate records of the versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_versions_metadata_filename = '../term-lists-versions/term-lists-versions.csv'\n",
    "term_lists_versions_metadata = readCsv(term_lists_versions_metadata_filename)\n",
    "print('Term lists versions metadata table headers and first row: ', term_lists_versions_metadata[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term lists versions members table tracks all of the term versions that are part of a particular version of a term list. It's used to generate `dcterms:hasPart` and `dcterms:isPartOf` links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_versions_members_filename = '../term-lists-versions/term-lists-versions-members.csv'\n",
    "term_lists_versions_members = readCsv(term_lists_versions_members_filename)\n",
    "print('Term lists versions members table headers and first row: ', term_lists_versions_members[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term lists versions replacements is used to generate the `dcterms:replaces` and `dcterms:isReplacedBy` links between term list versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_versions_replacements_filename = '../term-lists-versions/term-lists-versions-replacements.csv'\n",
    "term_lists_versions_replacements = readCsv(term_lists_versions_replacements_filename)\n",
    "print('Term lists versions replacements table headers and first row: ', term_lists_versions_replacements[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of datasets is used to enable a dump of the entire TDWG metadata dataset. The datasets are all of the directories in the rs.tdwg.org repo. Generally there are two datasets for every namespace in every vocabulary, one for the current terms and one for the term versions. There are also datasets for special resources like decisions, tdwgutility terms, term lists, vocabularies, and standards. The last modified dates need to be updated for these as well as new datasets must be added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_index_filename = '../index/index-datasets.csv'\n",
    "datasets_index = readCsv(datasets_index_filename)\n",
    "print('Dataset index table headers and first row: ', datasets_index[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Update tables\n",
    "\n",
    "Generate the URI for the new term list version.\n",
    "**Note:** need to trap for ideosyncratic URI pattern of `http://rs.tdwg.org/dwc/terms/attributes/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if namespaceUri == 'http://rs.tdwg.org/dwc/terms/attributes/':\n",
    "    termlistVersionUri = 'http://rs.tdwg.org/dwc/version/terms/attributes/' + date_issued\n",
    "else:\n",
    "    uriPieces = termlist_uri.split('/')\n",
    "    # split the URI between the vocabulary and term list subpaths\n",
    "    termlistVersionUri = uriPieces[0] + '//' + uriPieces[2] + '/' + uriPieces[3] + '/version/' + uriPieces[4] + '/' + date_issued\n",
    "    print(uriPieces)\n",
    "    print(termlistVersionUri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `list_modified` value for the focal term list. **Note:** Any modifications to the term list label or description needs to be done manually to the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_uri = findColumnWithHeader(term_lists_table[0], 'list')[1]\n",
    "list_created = findColumnWithHeader(term_lists_table[0], 'list_created')[1]\n",
    "list_modified = findColumnWithHeader(term_lists_table[0], 'list_modified')[1]\n",
    "modified_datetime = findColumnWithHeader(term_lists_table[0], 'document_modified')[1]\n",
    "standard_column = findColumnWithHeader(term_lists_table[0], 'standard')[1]\n",
    "list_description = findColumnWithHeader(term_lists_table[0], 'description')[1]\n",
    "\n",
    "aNewTermList = True\n",
    "for rowNumber in range(1, len(term_lists_table)):\n",
    "    # by convention, the namespace URI used for the terms is the same as the URI of the term list\n",
    "    if termlist_uri == term_lists_table[rowNumber][list_uri]:\n",
    "        aNewTermList = False\n",
    "        term_list_rowNumber = rowNumber\n",
    "        term_lists_table[rowNumber][list_modified] = date_issued\n",
    "        term_lists_table[rowNumber][modified_datetime] = isoTime(local_offset_from_utc)\n",
    "        # here is the opportunity to find out the standard URI for the modified term list\n",
    "        standardUri = term_lists_table[rowNumber][standard_column]\n",
    "        print(term_lists_table[rowNumber])\n",
    "if aNewTermList:  # this will happen if the term list did not previously exist\n",
    "    try:\n",
    "        new_term_list = readCsv('files_for_new/new_term_list.csv')\n",
    "    except:\n",
    "        print('The term list was not found and there was no new_term_list.csv file.')\n",
    "        sys.exit()\n",
    "    # Note: no error trapping is done here, so make sure that the new_term_list columns are the same as term_lists_table\n",
    "    new_term_list[1][modified_datetime] = isoTime(local_offset_from_utc)\n",
    "    new_term_list[1][list_created] = date_issued\n",
    "    new_term_list[1][list_modified] = date_issued\n",
    "    standardUri = new_term_list[1][standard_column]\n",
    "    # the length of the table (including header row) will be one more than the last row number\n",
    "    term_list_rowNumber = len(term_lists_table)\n",
    "    term_lists_table.append(new_term_list[1])\n",
    "    # after the new row is appended, its row number will be one more than the previous last row number\n",
    "    print('added a new term list row')\n",
    "    print(term_lists_table[term_list_rowNumber])\n",
    "    \n",
    "    # The new term list's dataset directory must be added to the dataset list. \n",
    "    row_for_current_terms = [isoTime(local_offset_from_utc), # document_modified\n",
    "                             database, # term_localName\n",
    "                             'http://rs.tdwg.org/index', # dcterms_isPartOf\n",
    "                             'http://rs.tdwg.org/index/' + database, # dataset_iri\n",
    "                             date_issued, # dcterms_modified\n",
    "                             new_term_list[1][list_description], # label\n",
    "                             ''] # rdfs_comment\n",
    "    datasets_index.append(row_for_current_terms)\n",
    "    \n",
    "    # New term lists will always have a new version dataset directory, so add it, too.\n",
    "    row_for_versions = [isoTime(local_offset_from_utc), # document_modified\n",
    "                        versions, # term_localName\n",
    "                        'http://rs.tdwg.org/index', # dcterms_isPartOf\n",
    "                        'http://rs.tdwg.org/index/' + versions, # dataset_iri\n",
    "                        date_issued, # dcterms_modified\n",
    "                        new_term_list[1][list_description] + ' versions', # label\n",
    "                        ''] # rdfs_comment\n",
    "    datasets_index.append(row_for_versions)\n",
    "    \n",
    "else: # If the term list isn't new, then its modified date needs to be updated.\n",
    "    # find the row in the dataset director file for the dataset being modified\n",
    "    for dataset_rownumber in range(1, len(datasets_index)):\n",
    "        # update current terms modified date\n",
    "        if database == datasets_index[dataset_rownumber][1]: # the name is in column 1\n",
    "            datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "            datasets_index[dataset_rownumber][4] = date_issued # the date modified is in column 4\n",
    "        # update versions modified date\n",
    "        if versions == datasets_index[dataset_rownumber][1]:\n",
    "            datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "            datasets_index[dataset_rownumber][4] = date_issued\n",
    "\n",
    "# Update the date for the term lists, term list versions, and all higher levels regardless of whether it's new or not\n",
    "for dataset_rownumber in range(1, len(datasets_index)):\n",
    "    if 'term-lists' == datasets_index[dataset_rownumber][1]:\n",
    "        datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "        datasets_index[dataset_rownumber][4] = date_issued\n",
    "    if 'term-lists-versions' == datasets_index[dataset_rownumber][1]:\n",
    "        datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "        datasets_index[dataset_rownumber][4] = date_issued\n",
    "    if 'vocabularies' == datasets_index[dataset_rownumber][1]:\n",
    "        datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "        datasets_index[dataset_rownumber][4] = date_issued\n",
    "    if 'vocabularies-versions' == datasets_index[dataset_rownumber][1]:\n",
    "        datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "        datasets_index[dataset_rownumber][4] = date_issued\n",
    "    if 'standards' == datasets_index[dataset_rownumber][1]:\n",
    "        datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "        datasets_index[dataset_rownumber][4] = date_issued\n",
    "    if 'standards-versions' == datasets_index[dataset_rownumber][1]:\n",
    "        datasets_index[dataset_rownumber][0] = isoTime(local_offset_from_utc)\n",
    "        datasets_index[dataset_rownumber][4] = date_issued\n",
    "        \n",
    "print()\n",
    "print('standard URI: ', standardUri)\n",
    "writeCsv('../term-lists/term-lists.csv', term_lists_table)\n",
    "writeCsv('../index/index-datasets.csv', datasets_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a row for the new term list version in the term list versions joins file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_lists_versions_joins.append([termlistVersionUri, termlist_uri])\n",
    "writeCsv('../term-lists/term-lists-versions.csv', term_lists_versions_joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add only the new terms to the term list members table. **When only deprecations are being made, skip this step and manually remove the deprecated term from the \"term-lists-members.csv\" file.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for newTerm in new_terms:\n",
    "    term_lists_members.append([termlist_uri, namespaceUri + newTerm])\n",
    "writeCsv('../term-lists/term-lists-members.csv', term_lists_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new term list version to the master term list version metadata file. The script assumes that all of the metadata remains the same as the previous version. If any values are different, change the CSV manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the columns than contain needed information\n",
    "list_uri = findColumnWithHeader(term_lists_versions_metadata[0], 'list')[1]\n",
    "document_modified = findColumnWithHeader(term_lists_versions_metadata[0], 'document_modified')[1]\n",
    "version_uri = findColumnWithHeader(term_lists_versions_metadata[0], 'version')[1]\n",
    "version_modified = findColumnWithHeader(term_lists_versions_metadata[0], 'version_modified')[1]\n",
    "status_column = findColumnWithHeader(term_lists_versions_metadata[0], 'status')[1]\n",
    "\n",
    "if aNewTermList:\n",
    "    # get the template for the term list version from first data row in the new_term_list_version.csv file\n",
    "    try:\n",
    "        new_term_list_version = readCsv('files_for_new/new_term_list_version.csv')\n",
    "    except:\n",
    "        print('The term list version was not found and there was no new_term_list_version.csv file.')\n",
    "        sys.exit()\n",
    "    newListRow = new_term_list_version[1]\n",
    "else:\n",
    "    # find the most recent previous version of the term list\n",
    "    mostRecent = 'a' # start the value of mostRecent as something earlier alphabetically than all of the list URIs\n",
    "    mostRecentListNumber = 0 # dummy list number to be replaced when most recent list is found\n",
    "    for termListRowNumber in range(1, len(term_lists_versions_metadata)):\n",
    "        # the row is one of the versions of the list\n",
    "        if term_lists_versions_metadata[termListRowNumber][list_uri] == termlist_uri:\n",
    "            # Make the version of the row the mostRecent if it's later than the previous mostRecent\n",
    "            if term_lists_versions_metadata[termListRowNumber][version_uri] > mostRecent:\n",
    "                mostRecent = term_lists_versions_metadata[termListRowNumber][version_uri]\n",
    "                mostRecentListNumber = termListRowNumber\n",
    "\n",
    "    # change the status of the most recent list to superseded\n",
    "    term_lists_versions_metadata[mostRecentListNumber][status_column] = 'superseded'\n",
    "    term_lists_versions_metadata[mostRecentListNumber][document_modified] = isoTime(local_offset_from_utc)\n",
    "\n",
    "    # start the new list row with the metadata from the most recent list\n",
    "    newListRow = copy.deepcopy(term_lists_versions_metadata[mostRecentListNumber])\n",
    "\n",
    "# substitute metadata to make the most recent list have the modified dates for the new list\n",
    "newListRow[document_modified] = isoTime(local_offset_from_utc)\n",
    "newListRow[version_uri] = termlistVersionUri\n",
    "newListRow[version_modified] = date_issued\n",
    "newListRow[status_column] = 'recommended'\n",
    "\n",
    "# append the new term list row to the old list of term lists\n",
    "term_lists_versions_metadata.append(newListRow)\n",
    "\n",
    "# save as a file\n",
    "writeCsv('../term-lists-versions/term-lists-versions.csv', term_lists_versions_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDWG minted terms ONLY\n",
    "\n",
    "**Do not run this code block for borrowed terms that do not have versions!** The placeholder term versions will have to be manually added under the new term list version URI.  See the various Audubon Core borrowed terms in the file for examples.\n",
    "\n",
    "Create the term list version members list for the new version of the term list.  This includes every pre-existing term version that hasn't changed, the new versions of terms that changed, and term versions for new terms that weren't previously on the list.\n",
    "\n",
    "**For term deprecations, run this step, then manually remove the last version of the deprecated term from the most recent term version list.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of every term version that was in the most recent previous list version\n",
    "newTermVersionMembersList = []\n",
    "# create a corresponding list of local names for those versions\n",
    "termLocalNameList = []\n",
    "\n",
    "if not aNewTermList:\n",
    "    for termVersion in term_lists_versions_members:\n",
    "        # the first column contains the term list version\n",
    "        if term_lists_versions_metadata[mostRecentListNumber][version_uri] == termVersion[0]:\n",
    "            newTermVersionMembersList.append(termVersion[1])\n",
    "\n",
    "            # dissect the term version URI to pull out the local name of the term version\n",
    "            pieces = termVersion[1].split('/')\n",
    "            versionLocalNamePiece = pieces[len(pieces)-1]\n",
    "            # split off the local name string from the issue date part of the version local name\n",
    "            termLocalNameList.append(versionLocalNamePiece.split('-')[0])\n",
    "\n",
    "    # For each modified term, find its previous version and replace it with the new version.\n",
    "    for modified_term in modified_terms:\n",
    "        for termVersionRowNumber in range(0, len(newTermVersionMembersList)):\n",
    "            if modified_term == termLocalNameList[termVersionRowNumber]:\n",
    "                # change the version on the list to the new one\n",
    "                newTermVersionMembersList[termVersionRowNumber] = namespaceUri + 'version/' + termLocalNameList[termVersionRowNumber] + '-' + date_issued\n",
    "\n",
    "# For each newly added term, add its new version to the list.\n",
    "for new_term in new_terms:\n",
    "    newTermVersionMembersList.append(namespaceUri + 'version/' + new_term + '-' + date_issued)\n",
    "\n",
    "# Now that the list is created of new term versions that are part of the new term version list,\n",
    "# add a record for each one to the term list versions members table\n",
    "for termVersionMember in newTermVersionMembersList:\n",
    "    term_lists_versions_members.append([termlistVersionUri, termVersionMember])\n",
    "\n",
    "# Write the updated term list versions members table to a file\n",
    "writeCsv('../term-lists-versions/term-lists-versions-members.csv', term_lists_versions_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a record to the term list versions replacements table showing that the new term list version has replaced the previous one (unless the term list is new and not replacing anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not aNewTermList:\n",
    "    term_lists_versions_replacements.append([termlistVersionUri, term_lists_versions_metadata[mostRecentListNumber][version_uri]])\n",
    "    writeCsv('../term-lists-versions/term-lists-versions-replacements.csv', term_lists_versions_replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Generate new vocabulary version\n",
    "\n",
    "**Note:** The code has been designed to avoid duplication of the same new vocabulary version in the case where the script has already been run for a different term list that was updated for the same vocabulary version.\n",
    "\n",
    "The update process is very similar to that of the term lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Open tables\n",
    "\n",
    "The types of tables related to vocabularies and their versions are very similar to those of term lists.  The are located in the directories `vocabularies` and `vocabularies-versions`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularies_table_filename = '../vocabularies/vocabularies.csv'\n",
    "vocabularies_table = readCsv(vocabularies_table_filename)\n",
    "print('Vocabularies table headers and first row: ', vocabularies_table[0:2])\n",
    "\n",
    "vocabularies_versions_joins_filename = '../vocabularies/vocabularies-versions.csv'\n",
    "vocabularies_versions_joins = readCsv(vocabularies_versions_joins_filename)\n",
    "print('Vocabularies versions joins table headers and first row: ', vocabularies_versions_joins[0:2])\n",
    "\n",
    "vocabularies_members_filename = '../vocabularies/vocabularies-members.csv'\n",
    "vocabularies_members = readCsv(vocabularies_members_filename)\n",
    "print('Vocabularies members table headers and first row: ', vocabularies_members[0:2])\n",
    "\n",
    "vocabularies_versions_metadata_filename = '../vocabularies-versions/vocabularies-versions.csv'\n",
    "vocabularies_versions_metadata = readCsv(vocabularies_versions_metadata_filename)\n",
    "print('Vocabularies versions metadata table headers and first row: ', vocabularies_versions_metadata[0:2])\n",
    "\n",
    "vocabularies_versions_members_filename = '../vocabularies-versions/vocabularies-versions-members.csv'\n",
    "vocabularies_versions_members = readCsv(vocabularies_versions_members_filename)\n",
    "print('Vocabularies versions members table headers and first row: ', vocabularies_versions_members[0:2])\n",
    "\n",
    "vocabularies_versions_replacements_filename = '../vocabularies-versions/vocabularies-versions-replacements.csv'\n",
    "vocabularies_versions_replacements = readCsv(vocabularies_versions_replacements_filename)\n",
    "print('Vocabularies versions replacements table headers and first row: ', vocabularies_versions_replacements[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Update tables\n",
    "\n",
    "**Note:** The steps here are analogous to updating term lists.\n",
    "\n",
    "Generate the URIs for the vocabulary and the new vocabulary version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the vocabulary subpath for the updated term list\n",
    "list_localName_column = findColumnWithHeader(term_lists_table[0], 'list_localName')[1]\n",
    "list_localName = term_lists_table[term_list_rowNumber][list_localName_column]\n",
    "print('List local name: ', list_localName)\n",
    "# the vocabulary subpath is the first part of the list local name\n",
    "vocab_subpath = list_localName.split('/')[0]\n",
    "print('Vocabulary subpath: ', vocab_subpath)\n",
    "termList_subpath = list_localName.split('/')[1]\n",
    "print('Term List subpath: ', termList_subpath)\n",
    "\n",
    "# generate the vocabulary URI\n",
    "vocabularyUri = 'http://rs.tdwg.org/' + vocab_subpath + '/'\n",
    "\n",
    "# generate the vocabulary version URI\n",
    "vocabularyVersionUri = 'http://rs.tdwg.org/version/' + vocab_subpath + '/' + date_issued\n",
    "print('New version URI: ', vocabularyVersionUri)\n",
    "\n",
    "# check for the case where the script was previously run to update a different term list in the same new vocabulary version\n",
    "temp = findColumnWithHeader(vocabularies_versions_metadata[0], 'version')[1]\n",
    "alreadyAddedVocab = False\n",
    "for versionRow in vocabularies_versions_metadata:\n",
    "    if versionRow[temp] == vocabularyVersionUri:\n",
    "        alreadyAddedVocab = True\n",
    "\n",
    "print('Already added : ', alreadyAddedVocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `vocabulary_modified` value for the focal vocabulary. **Note:** Any modifications to the vocabulary label or description needs to be done manually to the CSV file.  \n",
    "\n",
    "This code block doesn't really do anything in the case where a second term list is being added in the creation of a new vocabulary version, but it doesn't hurt to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_uri = findColumnWithHeader(vocabularies_table[0], 'vocabulary')[1]\n",
    "vocabulary_created = findColumnWithHeader(vocabularies_table[0], 'vocabulary_created')[1]\n",
    "vocabulary_modified = findColumnWithHeader(vocabularies_table[0], 'vocabulary_modified')[1]\n",
    "modified_datetime = findColumnWithHeader(vocabularies_table[0], 'document_modified')[1]\n",
    "\n",
    "aNewVocabulary = True\n",
    "for rowNumber in range(1, len(vocabularies_table)):\n",
    "    if vocabularyUri == vocabularies_table[rowNumber][vocabulary_uri]:\n",
    "        aNewVocabulary = False\n",
    "        vocabulary_rowNumber = rowNumber\n",
    "        # In the case where changes are made to a second term list of a new vocabulary, the new modified date will be the same as before\n",
    "        vocabularies_table[rowNumber][vocabulary_modified] = date_issued\n",
    "        vocabularies_table[rowNumber][modified_datetime] = isoTime(local_offset_from_utc)\n",
    "        print(vocabularies_table[rowNumber])\n",
    "\n",
    "if aNewVocabulary: # this will happen if the vocabulary did not previously exist \n",
    "    try:\n",
    "        new_vocabulary_row = readCsv('files_for_new/new_vocabulary.csv')[1]\n",
    "    except:\n",
    "        print('The vocabulary was not found and there was no new_vocabulary.csv file.')\n",
    "        sys.exit()\n",
    "    new_vocabulary_row[vocabulary_created] = date_issued\n",
    "    new_vocabulary_row[vocabulary_modified] = date_issued\n",
    "    new_vocabulary_row[modified_datetime] = isoTime(local_offset_from_utc)\n",
    "    vocabularies_table.append(new_vocabulary_row)\n",
    "\n",
    "writeCsv('../vocabularies/vocabularies.csv', vocabularies_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a row for the new vocabulary version in the vocabulary versions joins file. In cases where a second term list is being updated in the same new version of the vocabulary, the first term list will already have added the vocabulary version to the list, so it won't need to be added again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not alreadyAddedVocab:\n",
    "    vocabularies_versions_joins.append([vocabularyVersionUri, vocabularyUri])\n",
    "    writeCsv('../vocabularies/vocabularies-versions.csv', vocabularies_versions_joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to the vocabulary members table if there is a new term list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aNewTermList:\n",
    "    vocabularies_members.append([vocabularyUri, termlist_uri])\n",
    "    writeCsv('../vocabularies/vocabularies-members.csv', vocabularies_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add vocabulary version to the master vocabulary version metadata file. The script assumes that all of the metadata remains the same as the previous version. If any values are different, change the CSV manually.\n",
    "\n",
    "In cases where a second term list is being updated in the same new version of the vocabulary, the first term list will already have added the vocabulary version to the list, so it won't need to be added again.  That is, this code block won't really do anything new, but it doesn't hurt to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the columns than contain needed information\n",
    "vocabulary_uri = findColumnWithHeader(vocabularies_versions_metadata[0], 'vocabulary')[1]\n",
    "document_modified = findColumnWithHeader(vocabularies_versions_metadata[0], 'document_modified')[1]\n",
    "version_uri = findColumnWithHeader(vocabularies_versions_metadata[0], 'version')[1]\n",
    "version_issued = findColumnWithHeader(vocabularies_versions_metadata[0], 'version_issued')[1]\n",
    "status_column = findColumnWithHeader(vocabularies_versions_metadata[0], 'vocabulary_status')[1]\n",
    "\n",
    "if not alreadyAddedVocab:\n",
    "    if aNewVocabulary: # this will happen if the vocabulary did not previously exist \n",
    "        try:\n",
    "            newVocabularyRow = readCsv('files_for_new/new_vocabulary_version.csv')[1]\n",
    "        except:\n",
    "            print('The vocabulary version was not found and there was no new_vocabulary_version.csv file.')\n",
    "            sys.exit()\n",
    "        # the new row will be added to the end and therefore will have an index number - number of rows before appending\n",
    "        mostRecentVocabularyNumber = len(vocabularies_versions_metadata)\n",
    "    else:\n",
    "        # find the most recent previous version of the vocabulary\n",
    "        mostRecent = 'a' # start the value of mostRecent as something earlier alphabetically than all of the vocabulary version URIs\n",
    "        mostRecentVocabularyNumber = 0 # dummy vocabulary number to be replaced when most recent vocabulary version is found\n",
    "        for vocabularyRowNumber in range(1, len(vocabularies_versions_metadata)):\n",
    "            # the row is one of the versions of the vocabulary\n",
    "            if vocabularies_versions_metadata[vocabularyRowNumber][vocabulary_uri] == vocabularyUri:\n",
    "                # Make the version of the row the mostRecent if it's later than the previous mostRecent\n",
    "                if vocabularies_versions_metadata[vocabularyRowNumber][version_uri] > mostRecent:\n",
    "                    mostRecent = vocabularies_versions_metadata[vocabularyRowNumber][version_uri]\n",
    "                    mostRecentVocabularyNumber = vocabularyRowNumber\n",
    "\n",
    "        # change the status of the most recent vocabulary to superseded\n",
    "        vocabularies_versions_metadata[mostRecentVocabularyNumber][status_column] = 'superseded'\n",
    "        vocabularies_versions_metadata[mostRecentVocabularyNumber][document_modified] = isoTime(local_offset_from_utc)\n",
    "\n",
    "        # start the new vocabulary row with the metadata from the most recent vocabulary\n",
    "        newVocabularyRow = copy.deepcopy(vocabularies_versions_metadata[mostRecentVocabularyNumber])\n",
    "\n",
    "    # substitute metadata to make the most recent vocabulary have the modified dates for the new vocabulary\n",
    "    newVocabularyRow[document_modified] = isoTime(local_offset_from_utc)\n",
    "    newVocabularyRow[version_uri] = vocabularyVersionUri\n",
    "    newVocabularyRow[version_issued] = date_issued\n",
    "    newVocabularyRow[status_column] = 'recommended'\n",
    "\n",
    "    # append the new term list row to the old list of term lists\n",
    "    vocabularies_versions_metadata.append(newVocabularyRow)\n",
    "\n",
    "    # save as a file\n",
    "    writeCsv('../vocabularies-versions/vocabularies-versions.csv', vocabularies_versions_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the code block in the vocabulary section that MUST be run when more than one term list is being updated per version of the vocabulary!**\n",
    "\n",
    "Create the vocabularies versions members list for the new version of the vocabulary. This includes every pre-existing term list version that hasn't changed and the new version of the term list that changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is the second term list change for a new vocabulary version, the previous term list versions will already have been added.\n",
    "# So they don't need to be added to the list.  \n",
    "if not alreadyAddedVocab:\n",
    "    # create a list of every term list version that was in the most recent previous vocabulary version\n",
    "    newVocabularyMembersList = []\n",
    "    # create a corresponding list of local names for those term list versions\n",
    "    termListLocalNameList = []\n",
    "\n",
    "    if aNewVocabulary:\n",
    "        # the new term list version should be added to the list\n",
    "        newVocabularyMembersList.append(termlistVersionUri)\n",
    "    else:\n",
    "        # find all of the term list versions for the most recent vocabulary version\n",
    "        for termListVersion in vocabularies_versions_members:\n",
    "            # the first column contains the vocabulary version\n",
    "            if vocabularies_versions_metadata[mostRecentVocabularyNumber][version_uri] == termListVersion[0]:\n",
    "                newVocabularyMembersList.append(termListVersion[1])\n",
    "\n",
    "                # dissect the term list version URI to pull out the local name of the term list version\n",
    "                pieces = termListVersion[1].split('/')\n",
    "                versionLocalNamePiece = pieces[len(pieces)-2]\n",
    "                termListLocalNameList.append(versionLocalNamePiece)\n",
    "        if aNewTermList:\n",
    "            # the new term list version needs be added to the list\n",
    "            newVocabularyMembersList.append(termlistVersionUri)\n",
    "        else:\n",
    "            # For the modified term list, find its previous version and replace it with the new new version.\n",
    "            for termListVersionRowNumber in range(0, len(newVocabularyMembersList)):\n",
    "                if termList_subpath == termListLocalNameList[termListVersionRowNumber]:\n",
    "                    # change the term list version on the list to the new one\n",
    "                    newVocabularyMembersList[termListVersionRowNumber] = termlistVersionUri\n",
    "    \n",
    "    # Now that the list of new term list versions that are part of the new vocabulary version list is created,\n",
    "    # add a record for each one to the vocabulary versions members table\n",
    "    for termListVersionMember in newVocabularyMembersList:\n",
    "        vocabularies_versions_members.append([vocabularyVersionUri, termListVersionMember])\n",
    "\n",
    "# In the case where previous term list versions have already been added and a new vocabulary version already generated, \n",
    "# we only need to update the new term list version.\n",
    "else: \n",
    "    if aNewTermList:\n",
    "        # the new term list version needs be added to the list\n",
    "        vocabularies_versions_members.append([vocabularyVersionUri, termlistVersionUri])\n",
    "    else:\n",
    "        # For a modified term list, find its previous version and replace it with the new version.\n",
    "        for termListVersionRowNumber in range(1, len(vocabularies_versions_members)):\n",
    "            # consider only term lists that match the vocabulary version URI\n",
    "            if vocabularies_versions_members[termListVersionRowNumber][0] == vocabularyVersionUri:\n",
    "                # dissect the term list version URI to pull out the local name of the term list version\n",
    "                pieces = vocabularies_versions_members[termListVersionRowNumber][1].split('/')\n",
    "                versionLocalNamePiece = pieces[len(pieces)-2]\n",
    "                # check for a match of the term list version local name with the namespace string\n",
    "                if versionLocalNamePiece == namespace:\n",
    "                    # change the term list version on the list to the new one\n",
    "                    vocabularies_versions_members[termListVersionRowNumber][1] = termlistVersionUri\n",
    "    \n",
    "# Write the updated vocabularies versions members table to a file\n",
    "writeCsv('../vocabularies-versions/vocabularies-versions-members.csv', vocabularies_versions_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there was a prevous vocabulary version, add a record to the vocabulary versions replacements table showing that the new vocabulary version has replaced the previous one.  Also, don't repeat this if the new vocabulary version had already been added when a different term list had already been processed for this vocabulary version.\n",
    "\n",
    "So this code block doesn't need to be run if this is the second term list to be updated for a new vocabulary version. But it doesn't hurt to run it because it won't do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(aNewVocabulary) and not(alreadyAddedVocab):\n",
    "    vocabularies_versions_replacements.append([vocabularyVersionUri, vocabularies_versions_metadata[mostRecentVocabularyNumber][version_uri]])\n",
    "    writeCsv('../vocabularies-versions/vocabularies-versions-replacements.csv', vocabularies_versions_replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Generate new standard version\n",
    "\n",
    "**Note:** The script tries to avoid generating duplicate versions of a standard if the script was previously run on a different term list for some vocabulary in the standard.  There isn't really any reason to run any part of section 7 if this is the second term list added to a vocabulary.  However, running the cells shouldn't hurt anything.\n",
    "\n",
    "The update process is very similar to that of the vocabularies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Open tables\n",
    "\n",
    "The types of tables related to standards and their versions are very similar to those of vocabularies.  The are located in the directories `vocabularies` and `vocabularies-versions`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_table_filename = '../standards/standards.csv'\n",
    "standards_table = readCsv(standards_table_filename)\n",
    "print('Standards table headers and first row: ', standards_table[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_versions_joins_filename = '../standards/standards-versions.csv'\n",
    "standards_versions_joins = readCsv(standards_versions_joins_filename)\n",
    "print('Standards versions joins table headers and first row: ', standards_versions_joins[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_parts_filename = '../standards/standards-parts.csv'\n",
    "standards_parts = readCsv(standards_parts_filename)\n",
    "print('Standards parts table headers and first row: ', standards_parts[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_versions_metadata_filename = '../standards-versions/standards-versions.csv'\n",
    "standards_versions_metadata = readCsv(standards_versions_metadata_filename)\n",
    "print('Standards versions metadata table headers and first row: ', standards_versions_metadata[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_versions_parts_filename = '../standards-versions/standards-versions-parts.csv'\n",
    "standards_versions_parts = readCsv(standards_versions_parts_filename)\n",
    "print('Standards versions members table headers and first row: ', standards_versions_parts[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_versions_replacements_filename = '../standards-versions/standards-versions-replacements.csv'\n",
    "standards_versions_replacements = readCsv(standards_versions_replacements_filename)\n",
    "print('Standards versions replacements table headers and first row: ', standards_versions_replacements[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Update tables\n",
    "\n",
    "**Note:** The steps here are analogous to updating vocabularies.\n",
    "\n",
    "Generate the URIs for the standard and the new standard version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the standard URI (variable: standardUri) was already found in section 5.2 above\n",
    "print('Standard URI: ', standardUri)\n",
    "\n",
    "# find the standard number for the standard\n",
    "standard_number = standardUri.split('/')[4]\n",
    "print('Standard number: ', standard_number)\n",
    "\n",
    "# generate the standard version URI\n",
    "standardVersionUri = standardUri + '/version/' + date_issued\n",
    "print('New standard version URI: ', standardVersionUri)\n",
    "\n",
    "# check for the case where the script was previously run to update a different term list in the same new standard version\n",
    "temp = findColumnWithHeader(standards_versions_metadata[0], 'version')[1]\n",
    "alreadyAddedStandard = False\n",
    "for versionRow in standards_versions_metadata:\n",
    "    if versionRow[temp] == standardVersionUri:\n",
    "        alreadyAddedStandard = True\n",
    "\n",
    "print('Already added: ', alreadyAddedStandard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `standard_modified` value for the focal standard. **Note:** Any modifications to the standard label or description needs to be done manually to the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_uri = findColumnWithHeader(standards_table[0], 'standard')[1]\n",
    "standard_created = findColumnWithHeader(standards_table[0], 'standard_created')[1]\n",
    "standard_modified = findColumnWithHeader(standards_table[0], 'standard_modified')[1]\n",
    "modified_datetime = findColumnWithHeader(standards_table[0], 'document_modified')[1]\n",
    "\n",
    "aNewStandard = True\n",
    "for rowNumber in range(1, len(standards_table)):\n",
    "    if standardUri == standards_table[rowNumber][standard_uri]:\n",
    "        aNewStandard = False\n",
    "        standard_rowNumber = rowNumber\n",
    "        # in cases where changes are made to a second term list of a new standard, the new modified date will be the same as before\n",
    "        standards_table[rowNumber][standard_modified] = date_issued\n",
    "        standards_table[rowNumber][modified_datetime] = isoTime(local_offset_from_utc)\n",
    "        print(standards_table[rowNumber])\n",
    "\n",
    "if aNewStandard: # this will happen if the standard did not previously exist \n",
    "    try:\n",
    "        new_standard_row = readCsv('files_for_new/new_standard.csv')[1]\n",
    "    except:\n",
    "        print('The standard was not found and there was no new_standard.csv file.')\n",
    "        sys.exit()\n",
    "    new_standard_row[standard_created] = date_issued\n",
    "    new_standard_row[standard_modified] = date_issued\n",
    "    new_standard_row[modified_datetime] = isoTime(local_offset_from_utc)\n",
    "    # the row is set to what the last row will be after appending\n",
    "    standard_rowNumber = len(standards_table)\n",
    "    print('New standard added:')\n",
    "    print(new_standard_row)\n",
    "    standards_table.append(new_standard_row)\n",
    "\n",
    "writeCsv('../standards/standards.csv', standards_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a row for the new standard version in the standard versions joins file.  In cases where a second term list is being updated in the standard, the first term list will already have added the standard version to the list, so don't add it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not alreadyAddedStandard:\n",
    "    standards_versions_joins.append([standardVersionUri, standardUri])\n",
    "    writeCsv('../standards/standards-versions.csv', standards_versions_joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a new vocabulary, add it to the standards parts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aNewVocabulary:\n",
    "    standards_parts.append([standardUri, vocabularyUri, 'tdwgutility:Vocabulary'])\n",
    "    writeCsv('../standards/standards-parts.csv', standards_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add standard version to the master standard version metadata file. The script assumes that all of the metadata remains the same as the previous version. If any values are different, change the CSV manually.\n",
    "\n",
    "In cases where a second term list is being updated in the same new version of the standard, the first term list will have already added the standard version to the list, so it won't need to be added again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the columns than contain needed information\n",
    "standard_uri = findColumnWithHeader(standards_versions_metadata[0], 'standard')[1]\n",
    "document_modified = findColumnWithHeader(standards_versions_metadata[0], 'document_modified')[1]\n",
    "version_uri = findColumnWithHeader(standards_versions_metadata[0], 'version')[1]\n",
    "version_issued = findColumnWithHeader(standards_versions_metadata[0], 'version_issued')[1]\n",
    "status_column = findColumnWithHeader(standards_versions_metadata[0], 'standard_status')[1]\n",
    "\n",
    "if not alreadyAddedStandard:\n",
    "    if aNewStandard: # this will happen if the standard did not previously exist \n",
    "        try:\n",
    "            newStandardRow = readCsv('files_for_new/new_standard_version.csv')[1]\n",
    "        except:\n",
    "            print('The standard version was not found and there was no new_standard_version.csv file.')\n",
    "            sys.exit()\n",
    "        # the new row will be added to the end and therefore will have an index number - number of rows before appending\n",
    "        mostRecentStandardNumber = len(standards_versions_metadata)\n",
    "    else:\n",
    "        # find the most recent previous version of the standard\n",
    "        mostRecent = 'a' # start the value of mostRecent as something earlier alphabetically than all of the standard version URIs\n",
    "        mostRecentStandardNumber = 0 # dummy standard number to be replaced when most recent standard version is found\n",
    "        for standardRowNumber in range(1, len(standards_versions_metadata)):\n",
    "            # the row is one of the versions of the standard\n",
    "            if standards_versions_metadata[standardRowNumber][standard_uri] == standardUri:\n",
    "                # Make the version of the row the mostRecent if it's later than the previous mostRecent\n",
    "                if standards_versions_metadata[standardRowNumber][version_uri] > mostRecent:\n",
    "                    mostRecent = standards_versions_metadata[standardRowNumber][version_uri]\n",
    "                    mostRecentStandardNumber = standardRowNumber\n",
    "\n",
    "        # change the status of the most recent standard to superseded\n",
    "        standards_versions_metadata[mostRecentStandardNumber][status_column] = 'superseded'\n",
    "        standards_versions_metadata[mostRecentStandardNumber][document_modified] = isoTime(local_offset_from_utc)\n",
    "\n",
    "        # start the new standard row with the metadata from the most recent vocabulary\n",
    "        newStandardRow = copy.deepcopy(standards_versions_metadata[mostRecentStandardNumber])\n",
    "\n",
    "    # substitute metadata to make the most recent standard version have the modified dates for the new standard version\n",
    "    newStandardRow[document_modified] = isoTime(local_offset_from_utc)\n",
    "    newStandardRow[version_uri] = standardVersionUri\n",
    "    newStandardRow[version_issued] = date_issued\n",
    "    newStandardRow[status_column] = 'recommended'\n",
    "\n",
    "    # append the new term list row to the old list of term lists\n",
    "    standards_versions_metadata.append(newStandardRow)\n",
    "\n",
    "    # save as a file\n",
    "    writeCsv('../standards-versions/standards-versions.csv', standards_versions_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the standards versions members list for the new version of the standard. This includes every pre-existing vocabulary version that hasn't changed and the new version of the vocabulary that changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is the second term list change for a new standard version, the previous vocabulary version will have \n",
    "# been added.  So in that case the vocabulary versions need to be checked to prevent duplication.\n",
    "\n",
    "if not alreadyAddedStandard:\n",
    "    # create a list of every vocabulary version that was in the most recent previous standard version\n",
    "    newStandardMembersList = []\n",
    "    # create a corresponding list of local names for those term list versions\n",
    "    vocabularyLocalNameList = []\n",
    "\n",
    "    if aNewStandard:\n",
    "        # the new vocabulary version needs to be added to the list\n",
    "        newStandardMembersList.append(vocabularyVersionUri)\n",
    "    else:\n",
    "        # find the vocabulary versions for the most recent standard version\n",
    "        for vocabularyVersion in standards_versions_parts:\n",
    "            # the first column contains the standard version\n",
    "            if standards_versions_metadata[mostRecentStandardNumber][version_uri] == vocabularyVersion[0]:\n",
    "                newStandardMembersList.append(vocabularyVersion[1])\n",
    "\n",
    "                # dissect the vocabulary version URI to pull out the local name of the vocabulary version\n",
    "                pieces = vocabularyVersion[1].split('/')\n",
    "                versionLocalNamePiece = pieces[len(pieces)-2]\n",
    "                vocabularyLocalNameList.append(versionLocalNamePiece)\n",
    "\n",
    "        if aNewVocabulary:\n",
    "            # the new vocabulary version needs to be added to the list\n",
    "            newStandardMembersList.append(vocabularyVersionUri)\n",
    "        else:\n",
    "            # For the modified vocabulary, find its previous version and replace it with the new version.\n",
    "            for vocabularyVersionRowNumber in range(0, len(newStandardMembersList)):\n",
    "                if vocab_subpath == vocabularyLocalNameList[vocabularyVersionRowNumber]:\n",
    "                    # change the vocabulary version on the list to the new one\n",
    "                    newStandardMembersList[vocabularyVersionRowNumber] = vocabularyVersionUri\n",
    "\n",
    "    # Now that the list of new vocabulary versions that are part of the new standard version list is created,\n",
    "    # add a record for each one to the standard versions members table\n",
    "    for vocabularyVersionMember in newStandardMembersList:\n",
    "        standards_versions_parts.append([standardVersionUri, vocabularyVersionMember])\n",
    "        \n",
    "# In the case where previous vocabulary versions have already been added and a new standard version already generated\n",
    "# we only need to update the new vocabulary version\n",
    "else:\n",
    "    if aNewVocabulary:\n",
    "        # the new vocabulary version needs to be added to the list\n",
    "        standards_versions_parts.append([standardVersionUri, vocabularyVersionUri])\n",
    "    else:\n",
    "        # in this case a vocabulary is modified rather than new. So find its version under the current standard version\n",
    "        # and replace it with the new vocabulary version.  If the change was to a different term list but in the same\n",
    "        # standard, that's fine - the vocabulary version will be replaced with the same one and duplication will still\n",
    "        # be prevented\n",
    "        for vocabularyVersionRowNumber in range(0, len(standards_versions_parts)):\n",
    "            # consider only vocabularies that match the standard version URI\n",
    "            if standards_versions_parts[vocabularyVersionRowNumber][0] == standardVersionUri:\n",
    "                # dissect the vocabulary version URI to pull out the local name of the vocabulary version\n",
    "                pieces = standards_versions_parts[vocabularyVersionRowNumber][1].split('/')\n",
    "                versionLocalNamePiece = pieces[len(pieces)-2]\n",
    "                # check for a match of the vocabulary version local name with the vocabulary string\n",
    "                if versionLocalNamePiece == vocabulary:\n",
    "                    # change the vocabulary version on the list to the new one\n",
    "                    standards_versions_parts[vocabularyVersionRowNumber][1] = vocabularyVersionUri\n",
    "\n",
    "# Write the updated vocabularies versions members table to a file\n",
    "writeCsv('../standards-versions/standards-versions-parts.csv', standards_versions_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a record to the standard versions replacements table showing that the new standard version has replaced the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(aNewStandard) and not(alreadyAddedStandard):\n",
    "    standards_versions_replacements.append([standardVersionUri, standards_versions_metadata[mostRecentStandardNumber][version_uri]])\n",
    "    writeCsv('../standards-versions/standards-versions-replacements.csv', standards_versions_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
